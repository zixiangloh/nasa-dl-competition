{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17695539",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pygrib\n",
    "import os\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "import keras.backend as backend\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from dateutil import parser\n",
    "import matplotlib.pyplot as plt\n",
    "from pyhdf.SD import SD, SDC, SDS\n",
    "import pyproj\n",
    "from pyproj import CRS, Proj\n",
    "from typing import Union\n",
    "from shapely.geometry import Point, Polygon\n",
    "import geopandas as gpd\n",
    "from datetime import datetime, timedelta\n",
    "import pickle\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import KFold\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7320a7d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# column_names = ['datetime', 'latitude', 'humidity', 'temperature', 'wind_u', 'wind_v', 'precip']\n",
    "# df = pd.DataFrame(columns = column_names)\n",
    "\n",
    "weather_dict = {}\n",
    "counter = 0\n",
    "\n",
    "def listdirs(rootdir):\n",
    "    global weather_dict\n",
    "    global counter\n",
    "    for it in os.scandir(rootdir):\n",
    "        if it.is_dir():\n",
    "#             print(it.path)\n",
    "            listdirs(it)\n",
    "        \n",
    "        else:\n",
    "#             print(it, ' being added to dict')\n",
    "#             print(type(it))\n",
    "            grbs = pygrib.open(it.path)\n",
    "            for grb in grbs:\n",
    "                quad = (grb['dataDate'], grb['time'], grb['latitudes'], grb['parameterName'])\n",
    "                weather_dict[quad] = [grb['values']]\n",
    "                \n",
    "rootdir = './Actual Weather Data'\n",
    "listdirs(rootdir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2776e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "286\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2031586107.py:3: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  print(int(df2[20180202,0, 25.0]['Temperature']))\n"
     ]
    }
   ],
   "source": [
    "df = pd.DataFrame(weather_dict)\n",
    "df2 = df.sort_index()\n",
    "print(int(df2[20180202,0, 25.0]['Temperature']))\n",
    "# print(df2)\n",
    "\n",
    "# weather_dict[(20160202,0, 25.0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "466a40c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_weather_features(labels, weather_data_df, grid_id_list, training):\n",
    "    global features\n",
    "    counter = 0\n",
    "    for i in range(len(labels)):\n",
    "        grid_id = list(labels['grid_id'])[i]\n",
    "        j = grid_id_list.index(grid_id)\n",
    "        location = grid_metadata['location'][j]\n",
    "        tz = grid_metadata['tz'][j]\n",
    "        datetime = list(labels['datetime'])[j]\n",
    "        datetime_object = pd.to_datetime(\n",
    "            datetime,\n",
    "            format=\"%Y%m%dT%H:%M:%S\",\n",
    "            utc=True\n",
    "        )\n",
    "        \n",
    "        \n",
    "        datetime = datetime.replace('-', '')[:8]\n",
    "        yesterday = (datetime_object - timedelta(hours=24)).strftime('%Y%m%d')\n",
    "        \n",
    "        hours = [0, 600, 1200, 1800]\n",
    "        parameters = ['Relative humidity', 'Temperature', 'u-component of wind', 'v-component of wind', ]\n",
    "       \n",
    "        \n",
    "        if location == 'Delhi':\n",
    "            lat = 28.5\n",
    "        elif location == 'Los Angeles (SoCAB)':\n",
    "            lat = 34\n",
    "        elif location == 'Taipei':\n",
    "            lat = 25\n",
    "\n",
    "        features_to_add = []\n",
    "        for hour in hours:\n",
    "            temp = []\n",
    "            for param in parameters:\n",
    "                temp.append(int(weather_data_df[(int(yesterday), hour, lat\n",
    "                                            )][param]))\n",
    "            features_to_add.append(np.array(temp))\n",
    "            \n",
    "        for hour in hours:\n",
    "            temp = []\n",
    "            for param in parameters:\n",
    "                temp.append(int(weather_data_df[(int(datetime), hour, lat\n",
    "                                            )][param]))\n",
    "            features_to_add.append(np.array(temp))\n",
    "        \n",
    "        features.append(np.array(features_to_add))\n",
    "        counter+=1\n",
    "        if counter%100==0:\n",
    "            print(counter)\n",
    "#         print(features)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "76565f86",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_features_b(labels, weather_data_df, grid_id_list):\n",
    "    global features_b\n",
    "    for i in range(len(labels)):\n",
    "        grid_id = list(labels['grid_id'])[i]\n",
    "        j = grid_id_list.index(grid_id)\n",
    "        location = grid_metadata['location'][j]\n",
    "        datetime = list(labels['datetime'])[j]\n",
    "        \n",
    "        if (datetime[4:6]) in ['01','02','03']:\n",
    "            temp1 = [1,0,0,0]\n",
    "        elif datetime[4:6] in ['04','05','06']:\n",
    "            temp1 = [0,1,0,0]\n",
    "        elif datetime[4:6] in ['07', '08', '09']:\n",
    "            temp1 = [0,0,1,0]\n",
    "        else:\n",
    "            temp1 = [0,0,0,1]\n",
    "\n",
    "        if location == 'Los Angeles (SoCAB)':\n",
    "            temp2 = [1,0,0]\n",
    "        elif location == 'Delhi':\n",
    "            temp2 = [0,1,0]\n",
    "        else:\n",
    "            temp2 = [0,0,1]\n",
    "        \n",
    "        to_add = temp1 + temp2\n",
    "\n",
    "        features_b.append(to_add)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4c465e44",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:35: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(yesterday), hour, lat\n",
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:42: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(datetime), hour, lat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n",
      "13600\n",
      "13700\n",
      "13800\n",
      "13900\n",
      "14000\n",
      "14100\n",
      "14200\n",
      "14300\n",
      "14400\n",
      "14500\n",
      "14600\n",
      "14700\n",
      "14800\n",
      "14900\n",
      "15000\n",
      "15100\n",
      "15200\n",
      "15300\n",
      "15400\n",
      "15500\n",
      "15600\n",
      "15700\n",
      "15800\n",
      "15900\n",
      "16000\n",
      "16100\n",
      "16200\n",
      "16300\n",
      "16400\n",
      "16500\n",
      "16600\n",
      "16700\n",
      "16800\n",
      "16900\n",
      "17000\n",
      "17100\n",
      "17200\n",
      "17300\n",
      "17400\n",
      "17500\n",
      "17600\n",
      "17700\n"
     ]
    }
   ],
   "source": [
    "features = []\n",
    "features_b = []\n",
    "\n",
    "train_labels = pd.read_csv(\"train_labels.csv\")\n",
    "train_labels['Date'] = pd.to_datetime(train_labels['datetime'], format='%Y-%m-%d')\n",
    "train_labels['Year'] = train_labels['Date'].dt.year\n",
    "\n",
    "train_actual_labels = train_labels[train_labels['Year'] <= 2019].copy()\n",
    "train_cross_val_labels = train_labels[train_labels['Year'] > 2019].copy()\n",
    "\n",
    "# train_actual_labels = train_labels.head(750)\n",
    "# train_cross_val_labels = train_labels.tail(250)\n",
    "\n",
    "grid_metadata = pd.read_csv(\"grid_metadata.csv\", index_col=0)\n",
    "grid_id_list = list(grid_metadata['wkt'].keys())\n",
    "\n",
    "get_weather_features(train_actual_labels, df2, grid_id_list, True)\n",
    "get_features_b(train_actual_labels, df2, grid_id_list)\n",
    "\n",
    "train_features = features.copy()\n",
    "train_features_b = features_b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "831b7daf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found array with dim 3. MinMaxScaler expected <= 2.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [20]\u001b[0m, in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m scaler \u001b[38;5;241m=\u001b[39m MinMaxScaler()\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# transformed_features_actual_non_nan = scaler.fit_transform(features_train_actual_non_nan)\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m scaled_train_features \u001b[38;5;241m=\u001b[39m \u001b[43mscaler\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_features\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m scaled_train_features_b \u001b[38;5;241m=\u001b[39m scaler\u001b[38;5;241m.\u001b[39mfit_transform(train_features_b)\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/sklearn/base.py:852\u001b[0m, in \u001b[0;36mTransformerMixin.fit_transform\u001b[0;34m(self, X, y, **fit_params)\u001b[0m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;66;03m# non-optimized default implementation; override when a better\u001b[39;00m\n\u001b[1;32m    849\u001b[0m \u001b[38;5;66;03m# method is possible for a given clustering algorithm\u001b[39;00m\n\u001b[1;32m    850\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;66;03m# fit method of arity 1 (unsupervised transformation)\u001b[39;00m\n\u001b[0;32m--> 852\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mfit_params\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mtransform(X)\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;66;03m# fit method of arity 2 (supervised transformation)\u001b[39;00m\n\u001b[1;32m    855\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfit(X, y, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\u001b[38;5;241m.\u001b[39mtransform(X)\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:416\u001b[0m, in \u001b[0;36mMinMaxScaler.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    414\u001b[0m \u001b[38;5;66;03m# Reset internal state before fitting\u001b[39;00m\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()\n\u001b[0;32m--> 416\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpartial_fit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/sklearn/preprocessing/_data.py:453\u001b[0m, in \u001b[0;36mMinMaxScaler.partial_fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    447\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    448\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMinMaxScaler does not support sparse input. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    449\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConsider using MaxAbsScaler instead.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    450\u001b[0m     )\n\u001b[1;32m    452\u001b[0m first_pass \u001b[38;5;241m=\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mn_samples_seen_\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 453\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_validate_data\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfirst_pass\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[43mestimator\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mFLOAT_DTYPES\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[43mforce_all_finite\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mallow-nan\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    459\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    461\u001b[0m data_min \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmin(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    462\u001b[0m data_max \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mnanmax(X, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/sklearn/base.py:566\u001b[0m, in \u001b[0;36mBaseEstimator._validate_data\u001b[0;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[1;32m    564\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mValidation should be done on X, y or both.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    565\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m no_val_y:\n\u001b[0;32m--> 566\u001b[0m     X \u001b[38;5;241m=\u001b[39m \u001b[43mcheck_array\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcheck_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     out \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    568\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m no_val_X \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m no_val_y:\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/sklearn/utils/validation.py:794\u001b[0m, in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    790\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to convert array of bytes/strings \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    791\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minto decimal numbers with dtype=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnumeric\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    792\u001b[0m         ) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01me\u001b[39;00m\n\u001b[1;32m    793\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_nd \u001b[38;5;129;01mand\u001b[39;00m array\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m:\n\u001b[0;32m--> 794\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    795\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFound array with dim \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m expected <= 2.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    796\u001b[0m         \u001b[38;5;241m%\u001b[39m (array\u001b[38;5;241m.\u001b[39mndim, estimator_name)\n\u001b[1;32m    797\u001b[0m     )\n\u001b[1;32m    799\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m force_all_finite:\n\u001b[1;32m    800\u001b[0m     _assert_all_finite(array, allow_nan\u001b[38;5;241m=\u001b[39mforce_all_finite \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mallow-nan\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: Found array with dim 3. MinMaxScaler expected <= 2."
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "# transformed_features_actual_non_nan = scaler.fit_transform(features_train_actual_non_nan)\n",
    "\n",
    "# scaled_train_features = scaler.fit_transform(train_features)\n",
    "# scaled_train_features_b = scaler.fit_transform(train_features_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b4aea7cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import Input, Model\n",
    "from keras.layers import concatenate, GRU, BatchNormalization, Dropout\n",
    "\n",
    "inputA = Input(shape=(8,4))\n",
    "inputB = Input(shape=7)\n",
    "\n",
    "x = GRU(128, dropout=.20)(inputA)\n",
    "x = BatchNormalization()(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(.2)(x)\n",
    "x = Dense(10, activation='relu')(x)\n",
    "x = Model(inputs=inputA, outputs=x)\n",
    "\n",
    "y = Dense(64, activation='relu')(inputB)\n",
    "y = Dropout(.2)(y)\n",
    "y = Dense(10, activation='relu')(y)\n",
    "y = Model(inputs=inputB, outputs=y)\n",
    "\n",
    "combined = concatenate([x.output, y.output])\n",
    "\n",
    "z = Dense(64, activation='relu')(combined)\n",
    "z = Dropout(.2)(z)\n",
    "z = Dense(1, activation='linear')(z)\n",
    "\n",
    "model = Model(inputs=[x.input, y.input], outputs=z)\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3906421",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(17748, 8, 4) (17748, 7) (17748,)\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 15:39:17.476553: W tensorflow/core/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 3s 5ms/step - loss: 5323.0552\n",
      "Epoch 2/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4516.9565\n",
      "Epoch 3/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4458.0049\n",
      "Epoch 4/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4448.3477\n",
      "Epoch 5/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4456.3472\n",
      "Epoch 6/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4442.8340\n",
      "Epoch 7/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4426.1655\n",
      "Epoch 8/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4423.2563\n",
      "Epoch 9/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4423.9668\n",
      "Epoch 10/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4432.0962\n",
      "Epoch 11/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4423.0391\n",
      "Epoch 12/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4424.4131\n",
      "Epoch 13/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4432.8008\n",
      "Epoch 14/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4429.0352\n",
      "Epoch 15/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4424.4985\n",
      "Epoch 16/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4415.8398\n",
      "Epoch 17/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4429.1787\n",
      "Epoch 18/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4395.1279\n",
      "Epoch 19/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4429.6387\n",
      "Epoch 20/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4429.8633\n",
      "Epoch 21/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4424.4736\n",
      "Epoch 22/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4403.6729\n",
      "Epoch 23/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4402.6089\n",
      "Epoch 24/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4431.9634\n",
      "Epoch 25/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4410.4067\n",
      "Epoch 26/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4433.2856\n",
      "Epoch 27/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4431.7046\n",
      "Epoch 28/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4411.8154\n",
      "Epoch 29/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4391.5381\n",
      "Epoch 30/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4395.6128\n",
      "Epoch 31/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4418.4819\n",
      "Epoch 32/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4400.6748\n",
      "Epoch 33/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.6177\n",
      "Epoch 34/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4417.7363\n",
      "Epoch 35/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4423.2158\n",
      "Epoch 36/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4437.3916\n",
      "Epoch 37/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4394.3911\n",
      "Epoch 38/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4410.2349\n",
      "Epoch 39/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4404.7407\n",
      "Epoch 40/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4426.4043\n",
      "Epoch 41/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4427.3516\n",
      "Epoch 42/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4414.1162\n",
      "Epoch 43/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4421.9370\n",
      "Epoch 44/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.8042\n",
      "Epoch 45/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4424.1787\n",
      "Epoch 46/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4396.8203\n",
      "Epoch 47/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4397.7563\n",
      "Epoch 48/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4400.9976\n",
      "Epoch 49/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.0015\n",
      "Epoch 50/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4402.7773\n",
      "Epoch 51/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.6548\n",
      "Epoch 52/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4434.2515\n",
      "Epoch 53/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4427.7925\n",
      "Epoch 54/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4405.7007\n",
      "Epoch 55/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4374.7241\n",
      "Epoch 56/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4398.3726\n",
      "Epoch 57/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4410.1230\n",
      "Epoch 58/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4413.7388\n",
      "Epoch 59/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4395.4683\n",
      "Epoch 60/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4404.5835\n",
      "Epoch 61/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4383.6167\n",
      "Epoch 62/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4416.7764\n",
      "Epoch 63/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4395.8745\n",
      "Epoch 64/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4399.4946\n",
      "Epoch 65/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4431.1602\n",
      "Epoch 66/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4388.5430\n",
      "Epoch 67/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4380.7861\n",
      "Epoch 68/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4387.3047\n",
      "Epoch 69/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4397.6816\n",
      "Epoch 70/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4429.1553\n",
      "Epoch 71/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4394.2646\n",
      "Epoch 72/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4414.2524\n",
      "Epoch 73/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4406.5542\n",
      "Epoch 74/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4403.5713\n",
      "Epoch 75/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.6768\n",
      "Epoch 76/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4410.7754\n",
      "Epoch 77/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4391.6489\n",
      "Epoch 78/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4411.9341\n",
      "Epoch 79/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4393.5908\n",
      "Epoch 80/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4407.2490\n",
      "Epoch 81/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4405.4180\n",
      "Epoch 82/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4415.7339\n",
      "Epoch 83/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4398.7305\n",
      "Epoch 84/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4415.2329\n",
      "Epoch 85/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4381.0264\n",
      "Epoch 86/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4378.4546\n",
      "Epoch 87/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4396.7920\n",
      "Epoch 88/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4407.0308\n",
      "Epoch 89/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4407.6138\n",
      "Epoch 90/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4405.3452\n",
      "Epoch 91/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4402.0415\n",
      "Epoch 92/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4397.3291\n",
      "Epoch 93/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4393.0542\n",
      "Epoch 94/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4408.1455\n",
      "Epoch 95/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4384.2051\n",
      "Epoch 96/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "355/355 [==============================] - 2s 5ms/step - loss: 4401.0913\n",
      "Epoch 97/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4396.9517\n",
      "Epoch 98/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4377.9829\n",
      "Epoch 99/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4384.9023\n",
      "Epoch 100/100\n",
      "355/355 [==============================] - 2s 5ms/step - loss: 4402.0596\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x86ddd6020>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# !pip install pydot\n",
    "# !conda install graphviz\n",
    "from keras.layers import Dropout, GRU, BatchNormalization\n",
    "from keras.utils.vis_utils import plot_model\n",
    "import visualkeras\n",
    "import pydot\n",
    "\n",
    "labels_array = np.array(train_actual_labels.value)\n",
    "\n",
    "# def make_model():\n",
    "\n",
    "#     model = Sequential()\n",
    "#     model.add(Dense(13, input_dim=32, kernel_initializer='normal', activation='relu'))\n",
    "# #     model.add(Dropout(.2))\n",
    "#     model.add(Dense(6, kernel_initializer='normal', activation='relu'))\n",
    "# #     model.add(Dropout(.2))\n",
    "#     model.add(Dense(1, kernel_initializer='normal'))\n",
    "#     # Compile model\n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "# def make_model():\n",
    "#     model = Sequential()\n",
    "#     model.add(GRU(128, input_shape=(8, 4), dropout=.20))\n",
    "#     model.add(BatchNormalization())\n",
    "#     model.add(Dense(10, activation='relu'))\n",
    "#     model.add(Dropout(.2))\n",
    "#     model.add(Dense(1))\n",
    "    \n",
    "#     model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "#     return model\n",
    "\n",
    "\n",
    "# model = make_model()\n",
    "# plot_model(model)\n",
    "\n",
    "# estimator = KerasRegressor(build_fn=make_model, nb_epoch=100, batch_size=5, verbose=0)\n",
    "\n",
    "X = np.array(train_features)\n",
    "X_b = np.array(train_features_b)\n",
    "Y = np.array(labels_array)\n",
    "\n",
    "print(X.shape,X_b.shape,Y.shape)\n",
    "\n",
    "model.fit(x=[X, X_b], y=Y, epochs=100, batch_size=50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d94a15b8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:35: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(yesterday), hour, lat\n",
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:42: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(datetime), hour, lat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [16]\u001b[0m, in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m features \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m      6\u001b[0m features_b \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m----> 8\u001b[0m \u001b[43mget_weather_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtrain_cross_val_labels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrid_id_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m validation_features \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m     11\u001b[0m get_features_b(train_cross_val_labels, df2, grid_id_list)\n",
      "Input \u001b[0;32mIn [5]\u001b[0m, in \u001b[0;36mget_weather_features\u001b[0;34m(labels, weather_data_df, grid_id_list, training)\u001b[0m\n\u001b[1;32m     40\u001b[0m     temp \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     41\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m param \u001b[38;5;129;01min\u001b[39;00m parameters:\n\u001b[0;32m---> 42\u001b[0m         temp\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(\u001b[43mweather_data_df\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdatetime\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhour\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlat\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[43m                                    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m[param]))\n\u001b[1;32m     44\u001b[0m     features_to_add\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(temp))\n\u001b[1;32m     46\u001b[0m features\u001b[38;5;241m.\u001b[39mappend(np\u001b[38;5;241m.\u001b[39marray(features_to_add))\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/pandas/core/frame.py:3473\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3471\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[1;32m   3472\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n\u001b[0;32m-> 3473\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getitem_multilevel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3474\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_item_cache(key)\n\u001b[1;32m   3476\u001b[0m \u001b[38;5;66;03m# Do we have a slicer (on rows)?\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/pandas/core/frame.py:3555\u001b[0m, in \u001b[0;36mDataFrame._getitem_multilevel\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3553\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_getitem_multilevel\u001b[39m(\u001b[38;5;28mself\u001b[39m, key):\n\u001b[1;32m   3554\u001b[0m     \u001b[38;5;66;03m# self.columns is a MultiIndex\u001b[39;00m\n\u001b[0;32m-> 3555\u001b[0m     loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3556\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(loc, (\u001b[38;5;28mslice\u001b[39m, np\u001b[38;5;241m.\u001b[39mndarray)):\n\u001b[1;32m   3557\u001b[0m         new_columns \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns[loc]\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/pandas/core/indexes/multi.py:2915\u001b[0m, in \u001b[0;36mMultiIndex.get_loc\u001b[0;34m(self, key, method)\u001b[0m\n\u001b[1;32m   2909\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m follow_key:\n\u001b[1;32m   2910\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mslice\u001b[39m(start, stop)\n\u001b[1;32m   2912\u001b[0m warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   2913\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindexing past lexsort depth may impact performance.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   2914\u001b[0m     PerformanceWarning,\n\u001b[0;32m-> 2915\u001b[0m     stacklevel\u001b[38;5;241m=\u001b[39m\u001b[43mfind_stack_level\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m   2916\u001b[0m )\n\u001b[1;32m   2918\u001b[0m loc \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(start, stop, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp)\n\u001b[1;32m   2920\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(follow_key, \u001b[38;5;28mlen\u001b[39m(lead_key)):\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/site-packages/pandas/util/_exceptions.py:32\u001b[0m, in \u001b[0;36mfind_stack_level\u001b[0;34m()\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfind_stack_level\u001b[39m() \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mint\u001b[39m:\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;124;03m    Find the first place in the stack that is not inside pandas\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;124;03m    (tests notwithstanding).\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     stack \u001b[38;5;241m=\u001b[39m \u001b[43minspect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m     36\u001b[0m     pkg_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mdirname(pd\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:1678\u001b[0m, in \u001b[0;36mstack\u001b[0;34m(context)\u001b[0m\n\u001b[1;32m   1676\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstack\u001b[39m(context\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[1;32m   1677\u001b[0m     \u001b[38;5;124;03m\"\"\"Return a list of records for the stack above the caller's frame.\"\"\"\u001b[39;00m\n\u001b[0;32m-> 1678\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mgetouterframes\u001b[49m\u001b[43m(\u001b[49m\u001b[43msys\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_getframe\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:1655\u001b[0m, in \u001b[0;36mgetouterframes\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1653\u001b[0m framelist \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m   1654\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m frame:\n\u001b[0;32m-> 1655\u001b[0m     frameinfo \u001b[38;5;241m=\u001b[39m (frame,) \u001b[38;5;241m+\u001b[39m \u001b[43mgetframeinfo\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1656\u001b[0m     framelist\u001b[38;5;241m.\u001b[39mappend(FrameInfo(\u001b[38;5;241m*\u001b[39mframeinfo))\n\u001b[1;32m   1657\u001b[0m     frame \u001b[38;5;241m=\u001b[39m frame\u001b[38;5;241m.\u001b[39mf_back\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:1629\u001b[0m, in \u001b[0;36mgetframeinfo\u001b[0;34m(frame, context)\u001b[0m\n\u001b[1;32m   1627\u001b[0m start \u001b[38;5;241m=\u001b[39m lineno \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m context\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m\u001b[38;5;241m2\u001b[39m\n\u001b[1;32m   1628\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1629\u001b[0m     lines, lnum \u001b[38;5;241m=\u001b[39m \u001b[43mfindsource\u001b[49m\u001b[43m(\u001b[49m\u001b[43mframe\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1630\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m:\n\u001b[1;32m   1631\u001b[0m     lines \u001b[38;5;241m=\u001b[39m index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:940\u001b[0m, in \u001b[0;36mfindsource\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    932\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mfindsource\u001b[39m(\u001b[38;5;28mobject\u001b[39m):\n\u001b[1;32m    933\u001b[0m     \u001b[38;5;124;03m\"\"\"Return the entire source file and starting line number for an object.\u001b[39;00m\n\u001b[1;32m    934\u001b[0m \n\u001b[1;32m    935\u001b[0m \u001b[38;5;124;03m    The argument may be a module, class, method, function, traceback, frame,\u001b[39;00m\n\u001b[1;32m    936\u001b[0m \u001b[38;5;124;03m    or code object.  The source code is returned as a list of all the lines\u001b[39;00m\n\u001b[1;32m    937\u001b[0m \u001b[38;5;124;03m    in the file and the line number indexes a line in that list.  An OSError\u001b[39;00m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    is raised if the source code cannot be retrieved.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 940\u001b[0m     file \u001b[38;5;241m=\u001b[39m \u001b[43mgetsourcefile\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    941\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m file:\n\u001b[1;32m    942\u001b[0m         \u001b[38;5;66;03m# Invalidate cache if needed.\u001b[39;00m\n\u001b[1;32m    943\u001b[0m         linecache\u001b[38;5;241m.\u001b[39mcheckcache(file)\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:829\u001b[0m, in \u001b[0;36mgetsourcefile\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n\u001b[1;32m    828\u001b[0m \u001b[38;5;66;03m# only return a non-existent filename if the module has a PEP 302 loader\u001b[39;00m\n\u001b[0;32m--> 829\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mgetmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    830\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mgetattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__loader__\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    831\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m filename\n",
      "File \u001b[0;32m~/miniforge3/envs/nasa_conda/lib/python3.10/inspect.py:871\u001b[0m, in \u001b[0;36mgetmodule\u001b[0;34m(object, _filename)\u001b[0m\n\u001b[1;32m    869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ismodule(module) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m__file__\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m    870\u001b[0m     f \u001b[38;5;241m=\u001b[39m module\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__file__\u001b[39m\n\u001b[0;32m--> 871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m f \u001b[38;5;241m==\u001b[39m \u001b[43m_filesbymodname\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodname\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Have already mapped this module, so skip it\u001b[39;00m\n\u001b[1;32m    873\u001b[0m         \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    874\u001b[0m     _filesbymodname[modname] \u001b[38;5;241m=\u001b[39m f\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#Validating results\n",
    "\n",
    "\n",
    "# train_cross_val_labels = train_labels.tail(250)\n",
    "features = []\n",
    "features_b = []\n",
    "\n",
    "get_weather_features(train_cross_val_labels, df2, grid_id_list, True)\n",
    "validation_features = features.copy()\n",
    "\n",
    "get_features_b(train_cross_val_labels, df2, grid_id_list)\n",
    "validation_features_b = features_b.copy()\n",
    "\n",
    "predictions_2019 = model.predict([np.array(validation_features), np.array(validation_features_b)])\n",
    "\n",
    "print(mean_squared_error(np.array(train_cross_val_labels.value), predictions_2019))\n",
    "print(r2_score(train_cross_val_labels.value, predictions_2019))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210af930",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Debugging why the model isn't performing as it should\n",
    "\n",
    "for i in range(len(predictions_2019)):\n",
    "    print(i, predictions_2019[i], list(train_cross_val_labels.value)[i], \n",
    "          grid_metadata['location'][list(train_cross_val_labels['grid_id'])[i]], \n",
    "         list(train_cross_val_labels['datetime'])[i])\n",
    "# print(predictions_2019, train_cross_val_labels.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9a9cff01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:35: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(yesterday), hour, lat\n",
      "/var/folders/s9/bqp3gwh57sv7rgc2_ynsbcdm0000gn/T/ipykernel_51768/2959419267.py:42: PerformanceWarning: indexing past lexsort depth may impact performance.\n",
      "  temp.append(int(weather_data_df[(int(datetime), hour, lat\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n",
      "400\n",
      "500\n",
      "600\n",
      "700\n",
      "800\n",
      "900\n",
      "1000\n",
      "1100\n",
      "1200\n",
      "1300\n",
      "1400\n",
      "1500\n",
      "1600\n",
      "1700\n",
      "1800\n",
      "1900\n",
      "2000\n",
      "2100\n",
      "2200\n",
      "2300\n",
      "2400\n",
      "2500\n",
      "2600\n",
      "2700\n",
      "2800\n",
      "2900\n",
      "3000\n",
      "3100\n",
      "3200\n",
      "3300\n",
      "3400\n",
      "3500\n",
      "3600\n",
      "3700\n",
      "3800\n",
      "3900\n",
      "4000\n",
      "4100\n",
      "4200\n",
      "4300\n",
      "4400\n",
      "4500\n",
      "4600\n",
      "4700\n",
      "4800\n",
      "4900\n",
      "5000\n",
      "5100\n",
      "5200\n",
      "5300\n",
      "5400\n",
      "5500\n",
      "5600\n",
      "5700\n",
      "5800\n",
      "5900\n",
      "6000\n",
      "6100\n",
      "6200\n",
      "6300\n",
      "6400\n",
      "6500\n",
      "6600\n",
      "6700\n",
      "6800\n",
      "6900\n",
      "7000\n",
      "7100\n",
      "7200\n",
      "7300\n",
      "7400\n",
      "7500\n",
      "7600\n",
      "7700\n",
      "7800\n",
      "7900\n",
      "8000\n",
      "8100\n",
      "8200\n",
      "8300\n",
      "8400\n",
      "8500\n",
      "8600\n",
      "8700\n",
      "8800\n",
      "8900\n",
      "9000\n",
      "9100\n",
      "9200\n",
      "9300\n",
      "9400\n",
      "9500\n",
      "9600\n",
      "9700\n",
      "9800\n",
      "9900\n",
      "10000\n",
      "10100\n",
      "10200\n",
      "10300\n",
      "10400\n",
      "10500\n",
      "10600\n",
      "10700\n",
      "10800\n",
      "10900\n",
      "11000\n",
      "11100\n",
      "11200\n",
      "11300\n",
      "11400\n",
      "11500\n",
      "11600\n",
      "11700\n",
      "11800\n",
      "11900\n",
      "12000\n",
      "12100\n",
      "12200\n",
      "12300\n",
      "12400\n",
      "12500\n",
      "12600\n",
      "12700\n",
      "12800\n",
      "12900\n",
      "13000\n",
      "13100\n",
      "13200\n",
      "13300\n",
      "13400\n",
      "13500\n"
     ]
    }
   ],
   "source": [
    "#Getting predictions\n",
    "features = []\n",
    "features_b = []\n",
    "\n",
    "test_labels = pd.read_csv(\"submission_format.csv\") # Smallest subset\n",
    "grid_metadata = pd.read_csv(\"grid_metadata.csv\", index_col=0)\n",
    "\n",
    "grid_id_list = list(grid_metadata['wkt'].keys())\n",
    "\n",
    "get_weather_features(test_labels, df2, grid_id_list, True)\n",
    "get_features_b(test_labels, df2, grid_id_list)\n",
    "\n",
    "submission_features = features.copy()\n",
    "submission_features_b = features_b.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ede4aa32",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-03-21 18:30:18.328703: W tensorflow/python/util/util.cc:368] Sets are not currently considered sequences, but this may change in the future, so consider avoiding using them.\n",
      "WARNING:absl:Found untraced functions such as gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_fn, gru_cell_2_layer_call_and_return_conditional_losses, gru_cell_2_layer_call_and_return_conditional_losses while saving (showing 5 of 5). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8ec557e1-6459-45de-b9a0-b6097ba5b8ef/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: ram://8ec557e1-6459-45de-b9a0-b6097ba5b8ef/assets\n",
      "WARNING:absl:<keras.layers.recurrent.GRUCell object at 0x86b61a770> has the same name 'GRUCell' as a built-in Keras object. Consider renaming <class 'keras.layers.recurrent.GRUCell'> to avoid naming conflicts when loading with `tf.keras.models.load_model`. If renaming is not possible, pass the object in the `custom_objects` parameter of the load function.\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('final_features', 'wb') as f:\n",
    "    pickle.dump(submission_features, f)\n",
    "    \n",
    "with open('final_features_b', 'wb') as f:\n",
    "    pickle.dump(submission_features_b, f)\n",
    "    \n",
    "with open('weather_model', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa_conda",
   "language": "python",
   "name": "nasa_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
