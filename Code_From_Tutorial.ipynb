{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8cf378af",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Reference: https://www.drivendata.co/blog/predict-pm25-benchmark/\n",
    "\n",
    "pyhdf appears to be more powerful than gdal, so it may be worth adopting some of the \n",
    "methods used here for working with hdf files.\n",
    "\n",
    "Additionally, the tutorial shows how to make a masked numpy array, which allows us to work\n",
    "with sparse arrays? (I'm not sure how this works yet.)\n",
    "\n",
    "Finally, the tutorial explains how to align AOD data with coordinates. This could let us\n",
    "make some useful model features, like local weather conditions, etc.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from osgeo import gdal\n",
    "import numpy as np\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "import keras.backend as backend\n",
    "from keras.wrappers.scikit_learn import KerasRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from dateutil import parser\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "\n",
    "\n",
    "# from pathlib import Path\n",
    "# import random\n",
    "# from typing import Dict, List, Union\n",
    "\n",
    "# from cloudpathlib import S3Path\n",
    "import geopandas as gpd\n",
    "# import rasterio\n",
    "\n",
    "# DATA_PATH = Path.cwd().parent / \"data\"\n",
    "# RAW = DATA_PATH / \"raw\"\n",
    "# INTERIM = DATA_PATH / \"interim\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "eab9ce6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2018-02-01 17:25:00+00:00\n",
      "                    location             tz  \\\n",
      "grid_id                                       \n",
      "1X116                 Taipei    Asia/Taipei   \n",
      "1Z2W7                  Delhi  Asia/Calcutta   \n",
      "3S31A    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "6EIL6                  Delhi  Asia/Calcutta   \n",
      "7334C                  Delhi  Asia/Calcutta   \n",
      "78V83                  Delhi  Asia/Calcutta   \n",
      "7F1D1                  Delhi  Asia/Calcutta   \n",
      "8KNI6                  Delhi  Asia/Calcutta   \n",
      "90BZ1                 Taipei    Asia/Taipei   \n",
      "90S79                  Delhi  Asia/Calcutta   \n",
      "9Q6TA                 Taipei    Asia/Taipei   \n",
      "A2FBI    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "A7UCQ                  Delhi  Asia/Calcutta   \n",
      "AZJ0Z                  Delhi  Asia/Calcutta   \n",
      "C7PGV                  Delhi  Asia/Calcutta   \n",
      "CPR0W                  Delhi  Asia/Calcutta   \n",
      "D72OT                  Delhi  Asia/Calcutta   \n",
      "D7S1G                  Delhi  Asia/Calcutta   \n",
      "DHO4M    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "DJN0F    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "E2AUK                  Delhi  Asia/Calcutta   \n",
      "E5P9N    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "FRITQ    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "GAC6R                  Delhi  Asia/Calcutta   \n",
      "GJLB2                  Delhi  Asia/Calcutta   \n",
      "GVQXS                  Delhi  Asia/Calcutta   \n",
      "H96P6    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "HANW9                  Delhi  Asia/Calcutta   \n",
      "HM74A                  Delhi  Asia/Calcutta   \n",
      "IUMEZ                  Delhi  Asia/Calcutta   \n",
      "KW43U                 Taipei    Asia/Taipei   \n",
      "KZ9W9                  Delhi  Asia/Calcutta   \n",
      "NE7BV                  Delhi  Asia/Calcutta   \n",
      "P8JA5                  Delhi  Asia/Calcutta   \n",
      "PG3MI    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "PJNW1                  Delhi  Asia/Calcutta   \n",
      "PW0JT                  Delhi  Asia/Calcutta   \n",
      "QJHW4    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "S77YN                  Delhi  Asia/Calcutta   \n",
      "SZLMT                  Delhi  Asia/Calcutta   \n",
      "UC74Z                  Delhi  Asia/Calcutta   \n",
      "VBLD0    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "VR4WG                 Taipei    Asia/Taipei   \n",
      "VXNN3                  Delhi  Asia/Calcutta   \n",
      "VYH7U                  Delhi  Asia/Calcutta   \n",
      "WT52R    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "WZNCR                  Delhi  Asia/Calcutta   \n",
      "X5DKW    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "XJF9O                 Taipei    Asia/Taipei   \n",
      "XNLVD                 Taipei    Asia/Taipei   \n",
      "YHOPV                  Delhi  Asia/Calcutta   \n",
      "ZF3ZW                  Delhi  Asia/Calcutta   \n",
      "ZP1FZ    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "ZZ8JF    Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "\n",
      "                                                       wkt  \n",
      "grid_id                                                     \n",
      "1X116    POLYGON ((121.5257644471362 24.97766123020391,...  \n",
      "1Z2W7    POLYGON ((77.30453178416276 28.54664454217707,...  \n",
      "3S31A    POLYGON ((-117.9338248256995 33.79558357488509...  \n",
      "6EIL6    POLYGON ((77.07995296313287 28.54664454217707,...  \n",
      "7334C    POLYGON ((77.12486872733885 28.54664454217707,...  \n",
      "78V83    POLYGON ((76.94520567051495 28.54664454217707,...  \n",
      "7F1D1    POLYGON ((77.12486872733885 28.58609243100243,...  \n",
      "8KNI6    POLYGON ((77.30453178416276 28.46770443564941,...  \n",
      "90BZ1    POLYGON ((121.5706802113421 25.01836939334328,...  \n",
      "90S79    POLYGON ((77.21470025575081 28.62552552598286,...  \n",
      "9Q6TA    POLYGON ((121.5706802113421 25.05906406274214,...  \n",
      "A2FBI    POLYGON ((-117.3948356552278 33.98201108613195...  \n",
      "A7UCQ    POLYGON ((77.25961601995678 28.58609243100243,...  \n",
      "AZJ0Z    POLYGON ((77.25961601995678 28.70434728194878,...  \n",
      "C7PGV    POLYGON ((77.21470025575081 28.50718187266299,...  \n",
      "CPR0W    POLYGON ((77.30453178416276 28.66494381399507,...  \n",
      "D72OT    POLYGON ((77.16978449154482 28.70434728194878,...  \n",
      "D7S1G    POLYGON ((77.34944754836873 28.66494381399507,...  \n",
      "DHO4M    POLYGON ((-118.3380667035533 34.16803061743935...  \n",
      "DJN0F    POLYGON ((-117.6194144762577 34.09367183102137...  \n",
      "E2AUK    POLYGON ((77.0350371989269 28.58609243100243, ...  \n",
      "E5P9N    POLYGON ((-117.4846671836398 33.98201108613195...  \n",
      "FRITQ    POLYGON ((-118.1584036467294 33.83290166381627...  \n",
      "GAC6R    POLYGON ((77.12486872733885 28.74373591678664,...  \n",
      "GJLB2    POLYGON ((77.12486872733885 28.46770443564941,...  \n",
      "GVQXS    POLYGON ((77.21470025575081 28.66494381399507,...  \n",
      "H96P6    POLYGON ((-118.5177297603772 34.16803061743935...  \n",
      "HANW9    POLYGON ((77.21470025575081 28.54664454217707,...  \n",
      "HM74A    POLYGON ((77.12486872733885 28.66494381399507,...  \n",
      "IUMEZ    POLYGON ((77.25961601995678 28.62552552598286,...  \n",
      "KW43U    POLYGON ((121.6155959755481 25.01836939334328,...  \n",
      "KZ9W9    POLYGON ((77.16978449154482 28.62552552598286,...  \n",
      "NE7BV    POLYGON ((77.12486872733885 28.82246863505031,...  \n",
      "P8JA5    POLYGON ((77.25961601995678 28.54664454217707,...  \n",
      "PG3MI    POLYGON ((-118.2033194109354 34.05646791625069...  \n",
      "PJNW1    POLYGON ((77.21470025575081 28.70434728194878,...  \n",
      "PW0JT    POLYGON ((76.94520567051495 28.66494381399507,...  \n",
      "QJHW4    POLYGON ((-118.5177297603772 34.35364110514904...  \n",
      "S77YN    POLYGON ((77.07995296313287 28.70434728194878,...  \n",
      "SZLMT    POLYGON ((77.16978449154482 28.66494381399507,...  \n",
      "UC74Z    POLYGON ((77.30453178416276 28.50718187266299,...  \n",
      "VBLD0    POLYGON ((-118.2033194109354 33.87020346808818...  \n",
      "VR4WG    POLYGON ((121.5257644471362 25.05906406274214,...  \n",
      "VXNN3    POLYGON ((77.16978449154482 28.7831097054843, ...  \n",
      "VYH7U    POLYGON ((77.07995296313287 28.74373591678664,...  \n",
      "WT52R    POLYGON ((-116.8558464847561 33.9074889790035,...  \n",
      "WZNCR    POLYGON ((77.16978449154482 28.54664454217707,...  \n",
      "X5DKW    POLYGON ((-117.5744987120517 34.01924766510738...  \n",
      "XJF9O    POLYGON ((121.5257644471362 25.01836939334328,...  \n",
      "XNLVD    POLYGON ((121.5257644471362 25.09974522235117,...  \n",
      "YHOPV    POLYGON ((77.30453178416276 28.62552552598286,...  \n",
      "ZF3ZW    POLYGON ((77.07995296313287 28.66494381399507,...  \n",
      "ZP1FZ    POLYGON ((-117.8439932972876 34.13085940091023...  \n",
      "ZZ8JF    POLYGON ((-117.3050041268159 33.64614854761477...  \n"
     ]
    }
   ],
   "source": [
    "pm_md = pd.read_csv(\n",
    "    \"pm25_satellite_metadata.csv\",\n",
    "    parse_dates=[\"time_start\", \"time_end\"],\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "grid_md = pd.read_csv(\n",
    "    \"grid_metadata.csv\",\n",
    "    index_col=0\n",
    ")\n",
    "\n",
    "\n",
    "maiac_md = pm_md[(pm_md[\"product\"] == \"maiac\") & (pm_md[\"split\"] == \"train\")].copy()\n",
    "maiac_md.shape\n",
    "print(maiac_md['time_start']['20180201T191000_maiac_la_0.hdf'])\n",
    "pm_md.keys()\n",
    "print(grid_md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2838482",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13, 8)\n",
      "{'Optical_Depth_047': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 22, 0), 'Optical_Depth_055': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 22, 1), 'AOD_Uncertainty': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 22, 2), 'FineModeFraction': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 22, 3), 'Column_WV': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 22, 4), 'AOD_QA': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 23, 5), 'AOD_MODEL': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 21, 6), 'Injection_Height': (('Orbits:grid1km', 'YDim:grid1km', 'XDim:grid1km'), (4, 1200, 1200), 5, 7), 'cosSZA': (('Orbits:grid5km', 'YDim:grid5km', 'XDim:grid5km'), (4, 240, 240), 22, 8), 'cosVZA': (('Orbits:grid5km', 'YDim:grid5km', 'XDim:grid5km'), (4, 240, 240), 22, 9), 'RelAZ': (('Orbits:grid5km', 'YDim:grid5km', 'XDim:grid5km'), (4, 240, 240), 22, 10), 'Scattering_Angle': (('Orbits:grid5km', 'YDim:grid5km', 'XDim:grid5km'), (4, 240, 240), 22, 11), 'Glint_Angle': (('Orbits:grid5km', 'YDim:grid5km', 'XDim:grid5km'), (4, 240, 240), 22, 12)}\n"
     ]
    }
   ],
   "source": [
    "#Playing around with datasets\n",
    "\n",
    "from pyhdf.SD import SD, SDC, SDS\n",
    "import pyproj\n",
    "\n",
    "\n",
    "hdf = SD('train/20180201T191000_maiac_la_0.hdf')\n",
    "print(hdf.info())\n",
    "print(hdf.datasets())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b180647b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset name: Optical_Depth_047\n",
      "Number of dimensions: 3\n",
      "Shape: [4, 1200, 1200]\n",
      "Data type: 22\n",
      "Number of attributes: 6\n"
     ]
    }
   ],
   "source": [
    "blue_band_AOD = hdf.select(\"Optical_Depth_047\")\n",
    "name, num_dim, shape, types, num_attr = blue_band_AOD.info()\n",
    "print(\n",
    "f\"\"\"Dataset name: {name}\n",
    "Number of dimensions: {num_dim}\n",
    "Shape: {shape}\n",
    "Data type: {types}\n",
    "Number of attributes: {num_attr}\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f5cc3e0d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        ...,\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672]],\n",
       "\n",
       "       [[-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        ...,\n",
       "        [    21,     21,     21, ..., -28672, -28672, -28672],\n",
       "        [    22,     21,     21, ..., -28672, -28672, -28672],\n",
       "        [    24,     22,     21, ..., -28672, -28672, -28672]],\n",
       "\n",
       "       [[-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        ...,\n",
       "        [    73,     65,     53, ..., -28672, -28672, -28672],\n",
       "        [    62,     57,     51, ..., -28672, -28672, -28672],\n",
       "        [    56,     48,     41, ..., -28672, -28672, -28672]],\n",
       "\n",
       "       [[-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        ...,\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672],\n",
       "        [-28672, -28672, -28672, ..., -28672, -28672, -28672]]],\n",
       "      dtype=int16)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blue_band_AOD.get()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e0a8eab1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'long_name': 'AOD at 0.47 micron',\n",
       " 'scale_factor': 0.001,\n",
       " 'add_offset': 0.0,\n",
       " 'unit': 'none',\n",
       " '_FillValue': -28672,\n",
       " 'valid_range': [-100, 5000]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "calibration_dict = blue_band_AOD.attributes()\n",
    "calibration_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1c35f2b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'GROUP': 'MergedFields',\n",
       " 'END_GROUP': 'MergedFields',\n",
       " 'GridName': 'grid1km',\n",
       " 'XDim': 1200,\n",
       " 'YDim': 1200,\n",
       " 'UpperLeftPointMtrs': (-11119505.196667, 4447802.078667),\n",
       " 'LowerRightMtrs': (-10007554.677, 3335851.559),\n",
       " 'Projection': 'GCTP_SNSOID',\n",
       " 'ProjParams': (6371007.181, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0),\n",
       " 'SphereCode': -1,\n",
       " 'GridOrigin': 'HDFE_GD_UL',\n",
       " 'OBJECT': 'DataField_8',\n",
       " 'DimensionName': 'Orbits',\n",
       " 'Size': 4,\n",
       " 'END_OBJECT': 'DataField_8',\n",
       " 'DataFieldName': 'Injection_Height',\n",
       " 'DataType': 'DFNT_FLOAT32',\n",
       " 'DimList': ('Orbits', 'YDim', 'XDim')}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_attr = hdf.attributes()[\"StructMetadata.0\"]\n",
    "group_1 = raw_attr.split(\"END_GROUP=GRID_1\")[0]\n",
    "# print(group_1)\n",
    "\n",
    "hdf_metadata = dict([x.split(\"=\") for x in group_1.split() if \"=\" in x])\n",
    "\n",
    "# Parse expressions still wrapped in apostrophes\n",
    "for key, val in hdf_metadata.items():\n",
    "    try:\n",
    "        hdf_metadata[key] = eval(val)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "hdf_metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d7f75ad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'upper_left': (-11119505.196667, 4447802.078667),\n",
       " 'lower_right': (-10007554.677, 3335851.559),\n",
       " 'crs': 'GCTP_SNSOID',\n",
       " 'crs_params': (6371007.181, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that coordinates are provided in meters\n",
    "alignment_dict = {\n",
    "    \"upper_left\": hdf_metadata[\"UpperLeftPointMtrs\"],\n",
    "    \"lower_right\": hdf_metadata[\"LowerRightMtrs\"],\n",
    "    \"crs\": hdf_metadata[\"Projection\"],\n",
    "    \"crs_params\": hdf_metadata[\"ProjParams\"]\n",
    "}\n",
    "alignment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f74f276b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nDATA PROCESSING\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "DATA PROCESSING\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bbc06cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop over orbits to apply the attributes\n",
    "def calibrate_data(dataset: SDS, shape: list[int], calibration_dict: dict):\n",
    "    \"\"\"Given a MAIAC dataset and calibration parameters, return a masked\n",
    "    array of calibrated data.\n",
    "    \n",
    "    Args:\n",
    "        dataset (SDS): dataset in SDS format (e.g. blue band AOD).\n",
    "        shape (List[int]): dataset shape as a list of [orbits, height, width].\n",
    "        calibration_dict (Dict): dictionary containing, at a minimum,\n",
    "            `valid_range` (list or tuple), `_FillValue` (int or float),\n",
    "            `add_offset` (float), and `scale_factor` (float).\n",
    "    \n",
    "    Returns:\n",
    "        corrected_AOD (np.ma.MaskedArray): masked array of calibrated data\n",
    "            with a fill value of nan.\n",
    "    \"\"\"\n",
    "    corrected_AOD = np.ma.empty(shape, dtype=np.double)\n",
    "    for orbit in range(shape[0]):\n",
    "        data = dataset[orbit, :, :].astype(np.double)\n",
    "        invalid_condition = (\n",
    "            (data < calibration_dict[\"valid_range\"][0]) |\n",
    "            (data > calibration_dict[\"valid_range\"][1]) |\n",
    "            (data == calibration_dict[\"_FillValue\"])\n",
    "        )\n",
    "        data[invalid_condition] = np.nan\n",
    "        data = (\n",
    "            (data - calibration_dict[\"add_offset\"]) *\n",
    "            calibration_dict[\"scale_factor\"]\n",
    "        )\n",
    "        data = np.ma.masked_array(data, np.isnan(data))\n",
    "        corrected_AOD[orbit, : :] = data\n",
    "    corrected_AOD.fill_value = np.nan\n",
    "    return corrected_AOD\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3ff83d4d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "masked_array(\n",
       "  data=[[[--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]],\n",
       "\n",
       "        [[--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         ...,\n",
       "         [0.021, 0.021, 0.021, ..., --, --, --],\n",
       "         [0.022, 0.021, 0.021, ..., --, --, --],\n",
       "         [0.024, 0.022, 0.021, ..., --, --, --]],\n",
       "\n",
       "        [[--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         ...,\n",
       "         [0.073, 0.065, 0.053, ..., --, --, --],\n",
       "         [0.062, 0.057, 0.051000000000000004, ..., --, --, --],\n",
       "         [0.056, 0.048, 0.041, ..., --, --, --]],\n",
       "\n",
       "        [[--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         ...,\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --],\n",
       "         [--, --, --, ..., --, --, --]]],\n",
       "  mask=[[[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False, ...,  True,  True,  True],\n",
       "         [False, False, False, ...,  True,  True,  True],\n",
       "         [False, False, False, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [False, False, False, ...,  True,  True,  True],\n",
       "         [False, False, False, ...,  True,  True,  True],\n",
       "         [False, False, False, ...,  True,  True,  True]],\n",
       "\n",
       "        [[ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         ...,\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True],\n",
       "         [ True,  True,  True, ...,  True,  True,  True]]],\n",
       "  fill_value=nan)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrected_AOD = calibrate_data(blue_band_AOD, shape, calibration_dict)\n",
    "corrected_AOD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e30d2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AOD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1.203568e+06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>9.204344e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>6.629422e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>4.500000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>7.200000e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.220000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>5.940000e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                AOD\n",
       "count  1.203568e+06\n",
       "mean   9.204344e-02\n",
       "std    6.629422e-02\n",
       "min    0.000000e+00\n",
       "25%    4.500000e-02\n",
       "50%    7.200000e-02\n",
       "75%    1.220000e-01\n",
       "max    5.940000e-01"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(corrected_AOD.ravel(), columns=['AOD']).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8a4bdf9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Aligning AOD data with real world coordinates\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def create_meshgrid(alignment_dict: dict, shape: list[int]):\n",
    "    \"\"\"Given an image shape, create a meshgrid of points\n",
    "    between bounding coordinates.\n",
    "    \n",
    "    Args:\n",
    "        alignment_dict (Dict): dictionary containing, at a minimum,\n",
    "            `upper_left` (tuple), `lower_right` (tuple), `crs` (str),\n",
    "            and `crs_params` (tuple).\n",
    "        shape (List[int]): dataset shape as a list of\n",
    "            [orbits, height, width].\n",
    "    \n",
    "    Returns:\n",
    "        xv (np.array): x (longitude) coordinates.\n",
    "        yv (np.array): y (latitude) coordinates.\n",
    "    \"\"\"\n",
    "    # Determine grid bounds using two coordinates\n",
    "    x0, y0 = alignment_dict[\"upper_left\"]\n",
    "    x1, y1 = alignment_dict[\"lower_right\"]\n",
    "    \n",
    "    # Interpolate points between corners, inclusive of bounds\n",
    "    x = np.linspace(x0, x1, shape[2], endpoint=True)\n",
    "    y = np.linspace(y0, y1, shape[1], endpoint=True)\n",
    "    \n",
    "    # Return two 2D arrays representing X & Y coordinates of all points\n",
    "    xv, yv = np.meshgrid(x, y)\n",
    "    return xv, yv\n",
    "\n",
    "xv, yv = create_meshgrid(alignment_dict, shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ffe6a93",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyproj import CRS, Proj\n",
    "from typing import Union\n",
    "\n",
    "# Source: https://spatialreference.org/ref/sr-org/modis-sinusoidal/proj4js/\n",
    "sinu_crs = Proj(f\"+proj=sinu +R={alignment_dict['crs_params'][0]} +nadgrids=@null +wktext\").crs\n",
    "wgs84_crs = CRS.from_epsg(\"4326\")\n",
    "\n",
    "def transform_arrays(\n",
    "    xv: Union[np.array, float],\n",
    "    yv: Union[np.array, float],\n",
    "    crs_from: CRS,\n",
    "    crs_to: CRS\n",
    "):\n",
    "    \"\"\"Transform points or arrays from one CRS to another CRS.\n",
    "    \n",
    "    Args:\n",
    "        xv (np.array or float): x (longitude) coordinates or value.\n",
    "        yv (np.array or float): y (latitude) coordinates or value.\n",
    "        crs_from (CRS): source coordinate reference system.\n",
    "        crs_to (CRS): destination coordinate reference system.\n",
    "    \n",
    "    Returns:\n",
    "        lon, lat (tuple): x coordinate(s), y coordinate(s)\n",
    "    \"\"\"\n",
    "    transformer = pyproj.Transformer.from_crs(\n",
    "        crs_from,\n",
    "        crs_to,\n",
    "        always_xy=True,\n",
    "    )\n",
    "    lon, lat = transformer.transform(xv, yv)\n",
    "    return lon, lat\n",
    "\n",
    "\n",
    "\n",
    "# Project sinu grid onto wgs84 grid\n",
    "lon, lat = transform_arrays(xv, yv, sinu_crs, wgs84_crs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e22605e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7b97d960",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1203568, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>granule_id</th>\n",
       "      <th>orbit</th>\n",
       "      <th>geometry</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20180201T191000_maiac_la_0.hdf</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-110.79078 35.36280)</td>\n",
       "      <td>0.110</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20180201T191000_maiac_la_0.hdf</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-110.78956 35.35446)</td>\n",
       "      <td>0.076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20180201T191000_maiac_la_0.hdf</td>\n",
       "      <td>0</td>\n",
       "      <td>POINT (-110.28947 35.28774)</td>\n",
       "      <td>0.112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       granule_id  orbit                     geometry  value\n",
       "0  20180201T191000_maiac_la_0.hdf      0  POINT (-110.79078 35.36280)  0.110\n",
       "1  20180201T191000_maiac_la_0.hdf      0  POINT (-110.78956 35.35446)  0.076\n",
       "2  20180201T191000_maiac_la_0.hdf      0  POINT (-110.28947 35.28774)  0.112"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def convert_array_to_df(\n",
    "    corrected_arr: np.ma.MaskedArray,\n",
    "    lat:np.ndarray,\n",
    "    lon: np.ndarray,\n",
    "    granule_id: str,\n",
    "    crs: CRS,\n",
    "    total_bounds: np.ndarray = None\n",
    "):\n",
    "    \"\"\"Align data values with latitude and longitude coordinates\n",
    "    and return a GeoDataFrame.\n",
    "    \n",
    "    Args:\n",
    "        corrected_arr (np.ma.MaskedArray): data values for each pixel.\n",
    "        lat (np.ndarray): latitude for each pixel.\n",
    "        lon (np.ndarray): longitude for each pixel.\n",
    "        granule_id (str): granule name.\n",
    "        crs (CRS): coordinate reference system\n",
    "        total_bounds (np.ndarray, optional): If provided,\n",
    "            will filter out points that fall outside of these bounds.\n",
    "            Composed of xmin, ymin, xmax, ymax.\n",
    "    \"\"\"\n",
    "    lats = lat.ravel()\n",
    "    lons = lon.ravel()\n",
    "    n_orbits = len(corrected_arr)\n",
    "    size = lats.size\n",
    "    values = {\n",
    "        \"value\": np.concatenate([d.data.ravel() for d in corrected_arr]),\n",
    "        \"lat\": np.tile(lats, n_orbits),\n",
    "        \"lon\": np.tile(lons, n_orbits),\n",
    "        \"orbit\": np.arange(n_orbits).repeat(size),\n",
    "        \"granule_id\": [granule_id] * size * n_orbits\n",
    "        \n",
    "    }\n",
    "    \n",
    "    df = pd.DataFrame(values).dropna()\n",
    "    if total_bounds is not None:\n",
    "        x_min, y_min, x_max, y_max = total_bounds\n",
    "        df = df[df.lon.between(x_min, x_max) & df.lat.between(y_min, y_max)]\n",
    "    \n",
    "    gdf = gpd.GeoDataFrame(df)\n",
    "    gdf[\"geometry\"] = gpd.points_from_xy(gdf.lon, gdf.lat)\n",
    "    gdf.crs = crs\n",
    "    return gdf[[\"granule_id\", \"orbit\", \"geometry\", \"value\"]].reset_index(drop=True)\n",
    "\n",
    "gdf = convert_array_to_df(corrected_AOD, lat, lon, '20180201T191000_maiac_la_0.hdf', wgs84_crs)\n",
    "print(gdf.shape)\n",
    "gdf.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1d36508e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "Some more helpful functions from the tutorial\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "def create_calibration_dict(data: SDS):\n",
    "    \"\"\"Define calibration dictionary given a SDS dataset,\n",
    "    which contains:\n",
    "        - name\n",
    "        - scale factor\n",
    "        - offset\n",
    "        - unit\n",
    "        - fill value\n",
    "        - valid range\n",
    "    \n",
    "    Args:\n",
    "        data (SDS): dataset in the SDS format.\n",
    "    \n",
    "    Returns:\n",
    "        calibration_dict (Dict): dict of calibration parameters.\n",
    "    \"\"\"\n",
    "    return data.attributes()\n",
    "\n",
    "\n",
    "def create_alignment_dict(hdf: SD):\n",
    "    \"\"\"Define alignment dictionary given a SD data file, \n",
    "    which contains:\n",
    "        - upper left coordinates\n",
    "        - lower right coordinates\n",
    "        - coordinate reference system (CRS)\n",
    "        - CRS parameters\n",
    "    \n",
    "    Args:\n",
    "        hdf (SD): hdf data object\n",
    "    \n",
    "    Returns:\n",
    "        alignment_dict (Dict): dict of alignment parameters.\n",
    "    \"\"\"\n",
    "    group_1 = hdf.attributes()[\"StructMetadata.0\"].split(\"END_GROUP=GRID_1\")[0]\n",
    "    hdf_metadata = dict([x.split(\"=\") for x in group_1.split() if \"=\" in x])\n",
    "    alignment_dict = {\n",
    "        \"upper_left\": eval(hdf_metadata[\"UpperLeftPointMtrs\"]),\n",
    "        \"lower_right\": eval(hdf_metadata[\"LowerRightMtrs\"]),\n",
    "        \"crs\": hdf_metadata[\"Projection\"],\n",
    "        \"crs_params\": hdf_metadata[\"ProjParams\"]\n",
    "    }\n",
    "    return alignment_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1eed0c88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                          granule_id                time_start  \\\n",
      "0     20180201T191000_maiac_la_0.hdf  2018-02-01T17:25:00.000Z   \n",
      "1     20180202T195000_maiac_la_0.hdf  2018-02-02T18:05:00.000Z   \n",
      "2     20180203T203000_maiac_la_0.hdf  2018-02-03T17:10:00.000Z   \n",
      "3     20180204T194000_maiac_la_0.hdf  2018-02-04T17:55:00.000Z   \n",
      "4     20180205T202000_maiac_la_0.hdf  2018-02-05T17:00:00.000Z   \n",
      "...                              ...                       ...   \n",
      "4255  20201227T071500_maiac_dl_0.hdf  2020-12-27T05:25:00.000Z   \n",
      "4256  20201228T062000_maiac_dl_0.hdf  2020-12-28T06:10:00.000Z   \n",
      "4257  20201229T070000_maiac_dl_0.hdf  2020-12-29T05:15:00.000Z   \n",
      "4258  20201230T060500_maiac_dl_0.hdf  2020-12-30T05:55:00.000Z   \n",
      "4259  20201231T065000_maiac_dl_0.hdf  2020-12-31T05:00:00.000Z   \n",
      "\n",
      "                       time_end product location  split  \\\n",
      "0     2018-02-01 19:10:00+00:00   maiac       la  train   \n",
      "1     2018-02-02 19:50:00+00:00   maiac       la  train   \n",
      "2     2018-02-03 20:30:00+00:00   maiac       la  train   \n",
      "3     2018-02-04 19:40:00+00:00   maiac       la  train   \n",
      "4     2018-02-05 20:20:00+00:00   maiac       la  train   \n",
      "...                         ...     ...      ...    ...   \n",
      "4255  2020-12-27 07:15:00+00:00   maiac       dl  train   \n",
      "4256  2020-12-28 06:20:00+00:00   maiac       dl  train   \n",
      "4257  2020-12-29 07:00:00+00:00   maiac       dl  train   \n",
      "4258  2020-12-30 06:05:00+00:00   maiac       dl  train   \n",
      "4259  2020-12-31 06:50:00+00:00   maiac       dl  train   \n",
      "\n",
      "                                                 us_url  \\\n",
      "0     s3://drivendata-competition-airathon-public-us...   \n",
      "1     s3://drivendata-competition-airathon-public-us...   \n",
      "2     s3://drivendata-competition-airathon-public-us...   \n",
      "3     s3://drivendata-competition-airathon-public-us...   \n",
      "4     s3://drivendata-competition-airathon-public-us...   \n",
      "...                                                 ...   \n",
      "4255  s3://drivendata-competition-airathon-public-us...   \n",
      "4256  s3://drivendata-competition-airathon-public-us...   \n",
      "4257  s3://drivendata-competition-airathon-public-us...   \n",
      "4258  s3://drivendata-competition-airathon-public-us...   \n",
      "4259  s3://drivendata-competition-airathon-public-us...   \n",
      "\n",
      "                                                 eu_url  \\\n",
      "0     s3://drivendata-competition-airathon-public-eu...   \n",
      "1     s3://drivendata-competition-airathon-public-eu...   \n",
      "2     s3://drivendata-competition-airathon-public-eu...   \n",
      "3     s3://drivendata-competition-airathon-public-eu...   \n",
      "4     s3://drivendata-competition-airathon-public-eu...   \n",
      "...                                                 ...   \n",
      "4255  s3://drivendata-competition-airathon-public-eu...   \n",
      "4256  s3://drivendata-competition-airathon-public-eu...   \n",
      "4257  s3://drivendata-competition-airathon-public-eu...   \n",
      "4258  s3://drivendata-competition-airathon-public-eu...   \n",
      "4259  s3://drivendata-competition-airathon-public-eu...   \n",
      "\n",
      "                                                 as_url       cksum  \\\n",
      "0     s3://drivendata-competition-airathon-public-as...   911405771   \n",
      "1     s3://drivendata-competition-airathon-public-as...  2244451908   \n",
      "2     s3://drivendata-competition-airathon-public-as...  3799527997   \n",
      "3     s3://drivendata-competition-airathon-public-as...  4105997844   \n",
      "4     s3://drivendata-competition-airathon-public-as...  1805072340   \n",
      "...                                                 ...         ...   \n",
      "4255  s3://drivendata-competition-airathon-public-as...  3763818958   \n",
      "4256  s3://drivendata-competition-airathon-public-as...  1145735822   \n",
      "4257  s3://drivendata-competition-airathon-public-as...  1610883992   \n",
      "4258  s3://drivendata-competition-airathon-public-as...  2302045605   \n",
      "4259  s3://drivendata-competition-airathon-public-as...  2165921365   \n",
      "\n",
      "      granule_size  \n",
      "0         10446736  \n",
      "1         11090180  \n",
      "2         12468482  \n",
      "3         13064424  \n",
      "4         12549313  \n",
      "...            ...  \n",
      "4255      14099452  \n",
      "4256      12347688  \n",
      "4257      12772081  \n",
      "4258      13005795  \n",
      "4259      12181358  \n",
      "\n",
      "[4260 rows x 11 columns]\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "\n",
    "Importing HDF data and creating a set of raw hdf files.\n",
    "\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "train_labels = pd.read_csv(\"train_labels_100.csv\") # Smallest subset\n",
    "grid_metadata = pd.read_csv(\"grid_metadata.csv\")\n",
    "satellite_metadata = pd.read_csv(\"pm25_satellite_metadata.csv\")\n",
    "satellite_metadata = satellite_metadata[satellite_metadata.granule_id.str.endswith('f')]\n",
    "satellite_metadata = satellite_metadata[satellite_metadata['split'] == 'train']\n",
    "print(satellite_metadata)\n",
    "raw_hdf_set = set(satellite_metadata['granule_id'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "833abcbc",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "Everything here is original code that uses the functions from the tutorial.\n",
    "\n",
    "within(): taken from https://automating-gis-processes.github.io/2017/lessons/L3/point-in-polygon.html\n",
    "\n",
    "Make_Submatrix(): A function which takes raw AOD matrix and a Grid ID of interest as input and outputs a submatrix \n",
    "of AOD values which are inside this grid point (5km by 5km).\n",
    "\n",
    "Currently, Make_Submatrix() only returns the number of pixels in the AOD matrix are within the location determined\n",
    "by Grid ID.\n",
    "\n",
    "The rest of the code in this cell runs extremely slowly, but this is because we are running it for all possible \n",
    "combinations of HDF file and Grid ID. When we actually use these functions to run a model on a given Grid ID and \n",
    "datetime, we will first filter the set of HDF files such that we only search through HDF files with matching city \n",
    "and matching datetime.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#Helper function\n",
    "def Make_Poly(polyString):\n",
    "    poly_coords = []\n",
    "    for string in polyString.split(','):\n",
    "        split_string = string.split(' ')\n",
    "        if split_string[0] == 'POLYGON':\n",
    "            split_string = split_string[1:]\n",
    "            split_string[0] = str(split_string[0])[2:]\n",
    "    #         print(tuple(float(x) for x in split_string))\n",
    "        elif split_string[0] == '':\n",
    "            split_string = split_string[1:]\n",
    "        if split_string[1][-2] == ')':\n",
    "            split_string[1] = split_string[1][0:-2]\n",
    "        poly_coords.append(tuple(float(x) for x in split_string))\n",
    "\n",
    "    return Polygon(poly_coords)\n",
    "\n",
    "\n",
    "#Main function\n",
    "def Make_Submatrix(corrected_AOD, lon, lat, alignment_dict, grid_md, gridID):\n",
    "#     xv, yv = create_meshgrid(alignment_dict, shape)\n",
    "#     lon, lat = transform_arrays(xv, yv, sinu_crs, wgs84_crs)\n",
    "    \n",
    "    return_list = []\n",
    "    for band in range(len(corrected_AOD)):\n",
    "    \n",
    "        poly = Make_Poly(grid_md['wkt'][gridID])\n",
    "    #     counter = 0\n",
    "        triples_array = []\n",
    "        for i in range(len(corrected_AOD[0])):\n",
    "            for j in range(len(corrected_AOD[0][0])):\n",
    "                p1 = Point(lon[i,j], lat[i,j]) \n",
    "    #             print(p1, poly)\n",
    "                if(p1.within(poly)):\n",
    "                    triples_array.append((i, j, corrected_AOD[band,i,j])) #band 0 for now but hopefully this evolves \n",
    "\n",
    "        if len(triples_array) == 0:\n",
    "            return None\n",
    "\n",
    "        temp_array = np.zeros((10,10))\n",
    "        temp_array = np.ma.masked_array(temp_array, mask=np.ones((10,10)))\n",
    "\n",
    "        i_array = [x[0] for x in triples_array]\n",
    "        j_array = [x[1] for x in triples_array]\n",
    "        min_i = min(i_array)\n",
    "        min_j = min(j_array)\n",
    "\n",
    "\n",
    "\n",
    "        for triple in triples_array:\n",
    "            if triple[2] is np.ma.masked:\n",
    "                pass\n",
    "    #             return_array[triple[0]-min_i, triple[1]-min_j] = 'masked!!!'\n",
    "            else:\n",
    "                temp_array[triple[0]-min_i, triple[1]-min_j] = triple[2]\n",
    "        return_list.append(temp_array)\n",
    "\n",
    "#     number_of_bands_returned = len(return_list)\n",
    "    return return_list \n",
    "    \n",
    "#     if counter > 0:\n",
    "#         print(counter)\n",
    "            \n",
    "\n",
    "    \n",
    "    #     print(tuple(float(x) for x in split_string))\n",
    "#     print(triples_array)\n",
    "#     for i in range(3):\n",
    "#         plt.imshow(corrected_AOD[i])\n",
    "#         plt.show()\n",
    "    \n",
    "    \n",
    "# for hdf_filename in raw_hdf_set:\n",
    "#     print(hdf_filename)\n",
    "#     filepath = 'train/' + hdf_filename\n",
    "#     raw_hdf = SD(filepath)\n",
    "    \n",
    "#     alignment_dict = create_alignment_dict(raw_hdf)\n",
    "# #     print(alignment_dict['upper_left'], alignment_dict['lower_right'])\n",
    "    \n",
    "#     blue_band_AOD = raw_hdf.select(\"Optical_Depth_047\")\n",
    "#     name, num_dim, shape, types, num_attr = blue_band_AOD.info()\n",
    "#     calibration_dict = create_calibration_dict(blue_band_AOD)\n",
    "#     corrected_AOD = calibrate_data(blue_band_AOD, shape, calibration_dict)\n",
    "    \n",
    "#     xv, yv = create_meshgrid(alignment_dict, shape)\n",
    "#     lon, lat = transform_arrays(xv, yv, sinu_crs, wgs84_crs)\n",
    "    \n",
    "    \n",
    "#     for gridID in grid_md['wkt'].keys():\n",
    "#         Make_Submatrix(corrected_AOD, lon, lat, alignment_dict, grid_md, gridID)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1c5d371e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Note that each AOD_array in array_of_AOD_arrays should be a precalculated subarray corresponding to grid id\n",
    "def collect_features(array_of_AOD_arrays, area_per_subarray):\n",
    "    \n",
    "#     print('checkpoint 1')\n",
    "    \n",
    "    total_values = len(array_of_AOD_arrays)*area_per_subarray\n",
    "#     print(total_values, 'values')\n",
    "    \n",
    "    all_values = np.zeros((total_values))\n",
    "    all_values = np.ma.masked_array(all_values, mask=np.ones((total_values)))\n",
    "    \n",
    "#     print('checkpoint 2')\n",
    "    \n",
    "    counter = 0\n",
    "    for AOD_array in array_of_AOD_arrays:\n",
    "#         print('checkpoint 2.5')\n",
    "        for row in AOD_array:\n",
    "            for value in row:\n",
    "#                 print('checkpoint 2.6', value)\n",
    "                if not (value is np.ma.masked):\n",
    "#                     print('checkpoint 2.7')\n",
    "                    all_values[counter] = value\n",
    "                    counter+=1\n",
    "#                     print(all_values)\n",
    "            \n",
    "#     print('checkpoint 3')\n",
    "    \n",
    "    mean = np.ma.mean(all_values)\n",
    "    minimum = np.ma.min(all_values)\n",
    "    maximum = np.ma.max(all_values)\n",
    "    std = np.ma.std(all_values)\n",
    "    summ = np.ma.sum(all_values)\n",
    "    \n",
    "    print('done')\n",
    "    return(mean, minimum, maximum, std, summ)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8d45a92a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['datetime', 'grid_id', 'value'], dtype='object')\n",
      "['la' 'tpe' 'dl']\n",
      "['Taipei' 'Delhi' 'Los Angeles (SoCAB)']\n",
      "{'upper_left': (-11119505.196667, 4447802.078667), 'lower_right': (-10007554.677, 3335851.559), 'crs': 'GCTP_SNSOID', 'crs_params': (6371007.181, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0)}\n",
      "{'long_name': 'AOD at 0.47 micron', 'scale_factor': 0.001, 'add_offset': 0.0, 'unit': 'none', '_FillValue': -28672, 'valid_range': [-100, 5000]}\n",
      "                          granule_id                time_start  \\\n",
      "0     20180201T191000_maiac_la_0.hdf  2018-02-01T17:25:00.000Z   \n",
      "1     20180202T195000_maiac_la_0.hdf  2018-02-02T18:05:00.000Z   \n",
      "2     20180203T203000_maiac_la_0.hdf  2018-02-03T17:10:00.000Z   \n",
      "3     20180204T194000_maiac_la_0.hdf  2018-02-04T17:55:00.000Z   \n",
      "4     20180205T202000_maiac_la_0.hdf  2018-02-05T17:00:00.000Z   \n",
      "...                              ...                       ...   \n",
      "4255  20201227T071500_maiac_dl_0.hdf  2020-12-27T05:25:00.000Z   \n",
      "4256  20201228T062000_maiac_dl_0.hdf  2020-12-28T06:10:00.000Z   \n",
      "4257  20201229T070000_maiac_dl_0.hdf  2020-12-29T05:15:00.000Z   \n",
      "4258  20201230T060500_maiac_dl_0.hdf  2020-12-30T05:55:00.000Z   \n",
      "4259  20201231T065000_maiac_dl_0.hdf  2020-12-31T05:00:00.000Z   \n",
      "\n",
      "                       time_end product location  split  \\\n",
      "0     2018-02-01 19:10:00+00:00   maiac       la  train   \n",
      "1     2018-02-02 19:50:00+00:00   maiac       la  train   \n",
      "2     2018-02-03 20:30:00+00:00   maiac       la  train   \n",
      "3     2018-02-04 19:40:00+00:00   maiac       la  train   \n",
      "4     2018-02-05 20:20:00+00:00   maiac       la  train   \n",
      "...                         ...     ...      ...    ...   \n",
      "4255  2020-12-27 07:15:00+00:00   maiac       dl  train   \n",
      "4256  2020-12-28 06:20:00+00:00   maiac       dl  train   \n",
      "4257  2020-12-29 07:00:00+00:00   maiac       dl  train   \n",
      "4258  2020-12-30 06:05:00+00:00   maiac       dl  train   \n",
      "4259  2020-12-31 06:50:00+00:00   maiac       dl  train   \n",
      "\n",
      "                                                 us_url  \\\n",
      "0     s3://drivendata-competition-airathon-public-us...   \n",
      "1     s3://drivendata-competition-airathon-public-us...   \n",
      "2     s3://drivendata-competition-airathon-public-us...   \n",
      "3     s3://drivendata-competition-airathon-public-us...   \n",
      "4     s3://drivendata-competition-airathon-public-us...   \n",
      "...                                                 ...   \n",
      "4255  s3://drivendata-competition-airathon-public-us...   \n",
      "4256  s3://drivendata-competition-airathon-public-us...   \n",
      "4257  s3://drivendata-competition-airathon-public-us...   \n",
      "4258  s3://drivendata-competition-airathon-public-us...   \n",
      "4259  s3://drivendata-competition-airathon-public-us...   \n",
      "\n",
      "                                                 eu_url  \\\n",
      "0     s3://drivendata-competition-airathon-public-eu...   \n",
      "1     s3://drivendata-competition-airathon-public-eu...   \n",
      "2     s3://drivendata-competition-airathon-public-eu...   \n",
      "3     s3://drivendata-competition-airathon-public-eu...   \n",
      "4     s3://drivendata-competition-airathon-public-eu...   \n",
      "...                                                 ...   \n",
      "4255  s3://drivendata-competition-airathon-public-eu...   \n",
      "4256  s3://drivendata-competition-airathon-public-eu...   \n",
      "4257  s3://drivendata-competition-airathon-public-eu...   \n",
      "4258  s3://drivendata-competition-airathon-public-eu...   \n",
      "4259  s3://drivendata-competition-airathon-public-eu...   \n",
      "\n",
      "                                                 as_url       cksum  \\\n",
      "0     s3://drivendata-competition-airathon-public-as...   911405771   \n",
      "1     s3://drivendata-competition-airathon-public-as...  2244451908   \n",
      "2     s3://drivendata-competition-airathon-public-as...  3799527997   \n",
      "3     s3://drivendata-competition-airathon-public-as...  4105997844   \n",
      "4     s3://drivendata-competition-airathon-public-as...  1805072340   \n",
      "...                                                 ...         ...   \n",
      "4255  s3://drivendata-competition-airathon-public-as...  3763818958   \n",
      "4256  s3://drivendata-competition-airathon-public-as...  1145735822   \n",
      "4257  s3://drivendata-competition-airathon-public-as...  1610883992   \n",
      "4258  s3://drivendata-competition-airathon-public-as...  2302045605   \n",
      "4259  s3://drivendata-competition-airathon-public-as...  2165921365   \n",
      "\n",
      "      granule_size  \n",
      "0         10446736  \n",
      "1         11090180  \n",
      "2         12468482  \n",
      "3         13064424  \n",
      "4         12549313  \n",
      "...            ...  \n",
      "4255      14099452  \n",
      "4256      12347688  \n",
      "4257      12772081  \n",
      "4258      13005795  \n",
      "4259      12181358  \n",
      "\n",
      "[4260 rows x 11 columns]\n",
      "   grid_id             location             tz  \\\n",
      "0    1X116               Taipei    Asia/Taipei   \n",
      "1    1Z2W7                Delhi  Asia/Calcutta   \n",
      "2    3S31A  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "3    6EIL6                Delhi  Asia/Calcutta   \n",
      "4    7334C                Delhi  Asia/Calcutta   \n",
      "5    78V83                Delhi  Asia/Calcutta   \n",
      "6    7F1D1                Delhi  Asia/Calcutta   \n",
      "7    8KNI6                Delhi  Asia/Calcutta   \n",
      "8    90BZ1               Taipei    Asia/Taipei   \n",
      "9    90S79                Delhi  Asia/Calcutta   \n",
      "10   9Q6TA               Taipei    Asia/Taipei   \n",
      "11   A2FBI  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "12   A7UCQ                Delhi  Asia/Calcutta   \n",
      "13   AZJ0Z                Delhi  Asia/Calcutta   \n",
      "14   C7PGV                Delhi  Asia/Calcutta   \n",
      "15   CPR0W                Delhi  Asia/Calcutta   \n",
      "16   D72OT                Delhi  Asia/Calcutta   \n",
      "17   D7S1G                Delhi  Asia/Calcutta   \n",
      "18   DHO4M  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "19   DJN0F  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "20   E2AUK                Delhi  Asia/Calcutta   \n",
      "21   E5P9N  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "22   FRITQ  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "23   GAC6R                Delhi  Asia/Calcutta   \n",
      "24   GJLB2                Delhi  Asia/Calcutta   \n",
      "25   GVQXS                Delhi  Asia/Calcutta   \n",
      "26   H96P6  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "27   HANW9                Delhi  Asia/Calcutta   \n",
      "28   HM74A                Delhi  Asia/Calcutta   \n",
      "29   IUMEZ                Delhi  Asia/Calcutta   \n",
      "30   KW43U               Taipei    Asia/Taipei   \n",
      "31   KZ9W9                Delhi  Asia/Calcutta   \n",
      "32   NE7BV                Delhi  Asia/Calcutta   \n",
      "33   P8JA5                Delhi  Asia/Calcutta   \n",
      "34   PG3MI  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "35   PJNW1                Delhi  Asia/Calcutta   \n",
      "36   PW0JT                Delhi  Asia/Calcutta   \n",
      "37   QJHW4  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "38   S77YN                Delhi  Asia/Calcutta   \n",
      "39   SZLMT                Delhi  Asia/Calcutta   \n",
      "40   UC74Z                Delhi  Asia/Calcutta   \n",
      "41   VBLD0  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "42   VR4WG               Taipei    Asia/Taipei   \n",
      "43   VXNN3                Delhi  Asia/Calcutta   \n",
      "44   VYH7U                Delhi  Asia/Calcutta   \n",
      "45   WT52R  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "46   WZNCR                Delhi  Asia/Calcutta   \n",
      "47   X5DKW  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "48   XJF9O               Taipei    Asia/Taipei   \n",
      "49   XNLVD               Taipei    Asia/Taipei   \n",
      "50   YHOPV                Delhi  Asia/Calcutta   \n",
      "51   ZF3ZW                Delhi  Asia/Calcutta   \n",
      "52   ZP1FZ  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "53   ZZ8JF  Los Angeles (SoCAB)      Etc/GMT+8   \n",
      "\n",
      "                                                  wkt  \n",
      "0   POLYGON ((121.5257644471362 24.97766123020391,...  \n",
      "1   POLYGON ((77.30453178416276 28.54664454217707,...  \n",
      "2   POLYGON ((-117.9338248256995 33.79558357488509...  \n",
      "3   POLYGON ((77.07995296313287 28.54664454217707,...  \n",
      "4   POLYGON ((77.12486872733885 28.54664454217707,...  \n",
      "5   POLYGON ((76.94520567051495 28.54664454217707,...  \n",
      "6   POLYGON ((77.12486872733885 28.58609243100243,...  \n",
      "7   POLYGON ((77.30453178416276 28.46770443564941,...  \n",
      "8   POLYGON ((121.5706802113421 25.01836939334328,...  \n",
      "9   POLYGON ((77.21470025575081 28.62552552598286,...  \n",
      "10  POLYGON ((121.5706802113421 25.05906406274214,...  \n",
      "11  POLYGON ((-117.3948356552278 33.98201108613195...  \n",
      "12  POLYGON ((77.25961601995678 28.58609243100243,...  \n",
      "13  POLYGON ((77.25961601995678 28.70434728194878,...  \n",
      "14  POLYGON ((77.21470025575081 28.50718187266299,...  \n",
      "15  POLYGON ((77.30453178416276 28.66494381399507,...  \n",
      "16  POLYGON ((77.16978449154482 28.70434728194878,...  \n",
      "17  POLYGON ((77.34944754836873 28.66494381399507,...  \n",
      "18  POLYGON ((-118.3380667035533 34.16803061743935...  \n",
      "19  POLYGON ((-117.6194144762577 34.09367183102137...  \n",
      "20  POLYGON ((77.0350371989269 28.58609243100243, ...  \n",
      "21  POLYGON ((-117.4846671836398 33.98201108613195...  \n",
      "22  POLYGON ((-118.1584036467294 33.83290166381627...  \n",
      "23  POLYGON ((77.12486872733885 28.74373591678664,...  \n",
      "24  POLYGON ((77.12486872733885 28.46770443564941,...  \n",
      "25  POLYGON ((77.21470025575081 28.66494381399507,...  \n",
      "26  POLYGON ((-118.5177297603772 34.16803061743935...  \n",
      "27  POLYGON ((77.21470025575081 28.54664454217707,...  \n",
      "28  POLYGON ((77.12486872733885 28.66494381399507,...  \n",
      "29  POLYGON ((77.25961601995678 28.62552552598286,...  \n",
      "30  POLYGON ((121.6155959755481 25.01836939334328,...  \n",
      "31  POLYGON ((77.16978449154482 28.62552552598286,...  \n",
      "32  POLYGON ((77.12486872733885 28.82246863505031,...  \n",
      "33  POLYGON ((77.25961601995678 28.54664454217707,...  \n",
      "34  POLYGON ((-118.2033194109354 34.05646791625069...  \n",
      "35  POLYGON ((77.21470025575081 28.70434728194878,...  \n",
      "36  POLYGON ((76.94520567051495 28.66494381399507,...  \n",
      "37  POLYGON ((-118.5177297603772 34.35364110514904...  \n",
      "38  POLYGON ((77.07995296313287 28.70434728194878,...  \n",
      "39  POLYGON ((77.16978449154482 28.66494381399507,...  \n",
      "40  POLYGON ((77.30453178416276 28.50718187266299,...  \n",
      "41  POLYGON ((-118.2033194109354 33.87020346808818...  \n",
      "42  POLYGON ((121.5257644471362 25.05906406274214,...  \n",
      "43  POLYGON ((77.16978449154482 28.7831097054843, ...  \n",
      "44  POLYGON ((77.07995296313287 28.74373591678664,...  \n",
      "45  POLYGON ((-116.8558464847561 33.9074889790035,...  \n",
      "46  POLYGON ((77.16978449154482 28.54664454217707,...  \n",
      "47  POLYGON ((-117.5744987120517 34.01924766510738...  \n",
      "48  POLYGON ((121.5257644471362 25.01836939334328,...  \n",
      "49  POLYGON ((121.5257644471362 25.09974522235117,...  \n",
      "50  POLYGON ((77.30453178416276 28.62552552598286,...  \n",
      "51  POLYGON ((77.07995296313287 28.66494381399507,...  \n",
      "52  POLYGON ((-117.8439932972876 34.13085940091023...  \n",
      "53  POLYGON ((-117.3050041268159 33.64614854761477...  \n"
     ]
    }
   ],
   "source": [
    "print(train_labels.keys())\n",
    "print(satellite_metadata['location'].unique())\n",
    "print(grid_metadata['location'].unique())\n",
    "print(alignment_dict)\n",
    "print(calibration_dict)\n",
    "print(satellite_metadata)\n",
    "print(grid_metadata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b192e90",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n",
      "done\n",
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n",
      "done\n",
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n",
      "done\n",
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n",
      "done\n",
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n",
      "done\n",
      "['20180201T191000_maiac_la_0.hdf'] Los Angeles (SoCAB)\n",
      "next:\n"
     ]
    }
   ],
   "source": [
    "#Getting data to train the model\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "\n",
    "features = []\n",
    "train_labels = pd.read_csv(\"train_labels.csv\") # Smallest subset\n",
    "grid_metadata = pd.read_csv(\"grid_metadata.csv\")\n",
    "satellite_metadata = pd.read_csv(\"pm25_satellite_metadata.csv\")\n",
    "satellite_metadata = satellite_metadata[satellite_metadata.granule_id.str.endswith('f')]\n",
    "satellite_metadata = satellite_metadata[satellite_metadata['split'] == 'train'].copy()\n",
    "\n",
    "\n",
    "grid_id_list = list(grid_metadata['grid_id'])\n",
    "for i in range(len(train_labels)):\n",
    "    \n",
    "    satellite_metadata_cut = satellite_metadata\n",
    "    \n",
    "    grid_id = train_labels['grid_id'][i]\n",
    "    j = grid_id_list.index(grid_id)\n",
    "    location = grid_metadata['location'][j]\n",
    "    tz = grid_metadata['tz'][j]\n",
    "    datetime = pd.to_datetime(\n",
    "        train_labels['datetime'][j],\n",
    "        format=\"%Y%m%dT%H:%M:%S\",\n",
    "        utc=True\n",
    "    )\n",
    "    polygon = grid_metadata['wkt'][j]\n",
    "#     print(grid_id, datetime, location, timezone, polygon)\n",
    "    \n",
    "    if location == 'Delhi':\n",
    "        satellite_metadata_cut = satellite_metadata[satellite_metadata['location'] == 'dl'].copy()\n",
    "    elif location == 'Los Angeles (SoCAB)':\n",
    "        satellite_metadata_cut = satellite_metadata[satellite_metadata['location'] == 'la'].copy()\n",
    "    elif location == 'Taipei':\n",
    "        satellite_metadata_cut = satellite_metadata[satellite_metadata['location'] == 'tpe'].copy()\n",
    "        \n",
    "#     print(location, tz)\n",
    "#     print(len(satellite_metadata_cut))\n",
    "#     print(len(satellite_metadata))\n",
    "        \n",
    "    valid_datetime = [None]*len(satellite_metadata_cut)\n",
    "    satellite_metadata_cut.reset_index(drop=True, inplace=True) # ensure indexes pair with number of rows\n",
    "#     count = 0\n",
    "    for index, row in satellite_metadata_cut.iterrows():\n",
    "        \n",
    "        datetime1 = pd.to_datetime((row['time_start']), format=\"%Y%m%dT%H:%M:%S\", \n",
    "                                utc=True) #.tz_localize(None).tz_localize(tz)\n",
    "        datetime2 = pd.to_datetime(row['time_end'], format=\"%Y%m%dT%H:%M:%S\", \n",
    "                                            utc=True) #.tz_localize(None).tz_localize(tz)\n",
    "        \n",
    "#         print(index, datetime1.tzinfo)\n",
    "#         print(datetime2.tzinfo)\n",
    "\n",
    "#         print(datetime1, datetime, datetime2)\n",
    "        \n",
    "        truth1 = (datetime <= datetime2)\n",
    "        truth2 = datetime2 <= datetime + timedelta(hours=24)\n",
    "#         count+=1\n",
    "#         print(count)\n",
    "        valid_datetime[index] = (truth1 & truth2)\n",
    "#         if valid_datetime[index] == True:\n",
    "#             print('Yay!')\n",
    "    \n",
    "    \n",
    "    \n",
    "    satellite_metadata_cut['valid_datetime'] = valid_datetime\n",
    "    satellite_metadata_cut = satellite_metadata_cut[satellite_metadata_cut['valid_datetime'] == True]\n",
    "#     print(len(satellite_metadata_cut), location)\n",
    "#     print(satellite_metadata_cut['granule_id'])\n",
    "    raw_hdf_set = list(satellite_metadata_cut['granule_id']) #Note for now we are only including the first HDF;\n",
    "                                                          #Should make a function later which chooses the best HDF\n",
    "                                                          #File and the best band.\n",
    "    \n",
    "    \n",
    "    print(raw_hdf_set, location)\n",
    "    print('next:')\n",
    "    \n",
    "# \"\"\"\n",
    "    list_of_all_AOD_arrays = []\n",
    "    for hdf_filename in raw_hdf_set:\n",
    "#         print(hdf_filename)\n",
    "        filepath = 'train/' + hdf_filename\n",
    "#         print(filepath)\n",
    "        raw_hdf = SD(filepath)\n",
    "\n",
    "        alignment_dict = create_alignment_dict(raw_hdf)\n",
    "    #     print(alignment_dict['upper_left'], alignment_dict['lower_right'])\n",
    "\n",
    "        blue_band_AOD = raw_hdf.select(\"Optical_Depth_047\")\n",
    "        name, num_dim, shape, types, num_attr = blue_band_AOD.info()\n",
    "        calibration_dict = create_calibration_dict(blue_band_AOD)\n",
    "        corrected_AOD = calibrate_data(blue_band_AOD, shape, calibration_dict)\n",
    "\n",
    "        xv, yv = create_meshgrid(alignment_dict, shape)\n",
    "        lon, lat = transform_arrays(xv, yv, sinu_crs, wgs84_crs)\n",
    "\n",
    "        temp = Make_Submatrix(corrected_AOD, lon, lat, alignment_dict, grid_md, grid_id)\n",
    "        for AOD_array in temp:\n",
    "            list_of_all_AOD_arrays.append(AOD_array)\n",
    "            \n",
    "    features.append(np.array(collect_features(list_of_all_AOD_arrays, 100)))\n",
    "    \n",
    "# \"\"\"\n",
    "print(features)\n",
    "\n",
    "# Etc/GMT+8\n",
    "    \n",
    "    \n",
    "\n",
    "# print(train_labels[train_labels['grid_id'] == '1X116']) demonstration of the fact that grids are repeated at \n",
    "#different datetimes.\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48727e06",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nasa_conda",
   "language": "python",
   "name": "nasa_conda"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
